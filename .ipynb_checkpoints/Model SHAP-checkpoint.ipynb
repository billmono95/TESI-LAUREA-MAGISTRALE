{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import math \n",
    "from math import floor\n",
    "from scipy.stats.mstats import winsorize\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "# Deep learning library, used for neural networks\n",
    "from keras.models import Sequential \n",
    "# Deep learning classes for recurrent and regular densely-connected layers\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "# EarlyStopping during model training\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puoi scegliere fino a quando guardare in avanti con la previsione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_len = math.ceil(df_return2.shape[0] * 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,test_df = df_return2[1:train_data_len], df_return2[train_data_len:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ETH</th>\n",
       "      <th>BTC</th>\n",
       "      <th>XRP</th>\n",
       "      <th>LTC</th>\n",
       "      <th>XLM</th>\n",
       "      <th>Palladium</th>\n",
       "      <th>Gold</th>\n",
       "      <th>HSI</th>\n",
       "      <th>N225</th>\n",
       "      <th>SP500</th>\n",
       "      <th>NVIDIA</th>\n",
       "      <th>AMD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-07-03</th>\n",
       "      <td>-0.017438</td>\n",
       "      <td>-0.003958</td>\n",
       "      <td>-0.005123</td>\n",
       "      <td>-0.006749</td>\n",
       "      <td>-0.016914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009908</td>\n",
       "      <td>0.007248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-04</th>\n",
       "      <td>0.016327</td>\n",
       "      <td>0.004973</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.020869</td>\n",
       "      <td>0.009190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ETH       BTC       XRP       LTC       XLM  Palladium  Gold  \\\n",
       "Date                                                                            \n",
       "2020-07-03 -0.017438 -0.003958 -0.005123 -0.006749 -0.016914        0.0   0.0   \n",
       "2020-07-04  0.016327  0.004973  0.009346  0.020869  0.009190        0.0   0.0   \n",
       "\n",
       "                 HSI      N225  SP500  NVIDIA  AMD  \n",
       "Date                                                \n",
       "2020-07-03  0.009908  0.007248    0.0     0.0  0.0  \n",
       "2020-07-04  0.000000  0.000000    0.0     0.0  0.0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_series(series, n_past, n_future):\n",
    "  #\n",
    "  # n_past ==> no of past observations\n",
    "  #\n",
    "  # n_future ==> no of future observations \n",
    "  #\n",
    "    X, y = list(), list()\n",
    "    for window_start in range(len(series)):\n",
    "        past_end = window_start + n_past\n",
    "        future_end = past_end + n_future\n",
    "        if future_end > len(series):\n",
    "              break\n",
    "    # slicing the past and future parts of the window\n",
    "        past, future = series[window_start:past_end, :], series[past_end:future_end, :]\n",
    "        X.append(past)\n",
    "        y.append(future)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_past = 3\n",
    "n_future = 1 \n",
    "n_features = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = split_series(train_df.values,n_past, n_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1],n_features))\n",
    "y_train = y_train.reshape((y_train.shape[0], y_train.shape[1], n_features))\n",
    "X_test, y_test = split_series(test_df.values,n_past, n_future)\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1],n_features))\n",
    "y_test = y_test.reshape((y_test.shape[0], y_test.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00450926, -0.00260916,  0.01443437, -0.00857143, -0.01544622,\n",
       "        -0.01552738,  0.00297619, -0.00648932, -0.00417216,  0.00129411,\n",
       "         0.01606426, -0.00722022],\n",
       "       [ 0.00071987, -0.00659783, -0.00678359, -0.00576369, -0.02847182,\n",
       "        -0.02391073,  0.0083792 , -0.0098123 , -0.00994229, -0.01243022,\n",
       "        -0.03617875, -0.04424779],\n",
       "       [-0.00931262,  0.04387689,  0.005997  ,  0.04347826,  0.03349282,\n",
       "        -0.02385902,  0.0083792 , -0.01570424, -0.01520277, -0.01243022,\n",
       "        -0.03617875, -0.04424779]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00931262,  0.04387689,  0.005997  ,  0.04347826,  0.03349282,\n",
       "        -0.02385902,  0.0083792 , -0.01570424, -0.01520277, -0.01243022,\n",
       "        -0.03617875, -0.04424779]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NUOVO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = df_return2.shape[0]\n",
    "np_data = np.reshape(np.array(df_return2), (nrows, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1826, 12)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1643, 1, 12) (1643,)\n",
      "(182, 1, 12) (182,)\n",
      "-0.007913436692506437\n",
      "-0.007913436692506437\n"
     ]
    }
   ],
   "source": [
    "# Set the sequence length - this is the timeframe used to make a single prediction\n",
    "sequence_length = 1 # = number of neurons in the first layer of the neural network\n",
    "\n",
    "# Prediction Index\n",
    "index_Close = 1\n",
    "\n",
    "# Split the training data into train and train data sets\n",
    "# As a first step, we get the number of rows to train the model on 80% of the data \n",
    "train_data_len = math.ceil(np_data.shape[0] * 0.9)\n",
    "\n",
    "# Create the training and test data\n",
    "train_data = np_data[0:train_data_len, :]\n",
    "test_data = np_data[train_data_len - sequence_length:, :]\n",
    "\n",
    "# The RNN needs data with the format of [samples, time steps, features]\n",
    "# Here, we create N samples, sequence_length time steps per sample, and 6 features\n",
    "def partition_dataset(sequence_length, data):\n",
    "    x, y = [], []\n",
    "    data_len = data.shape[0]\n",
    "    for i in range(sequence_length, data_len):\n",
    "        x.append(data[i-sequence_length:i,:]) #contains sequence_length values 0-sequence_length * columsn\n",
    "        y.append(data[i, index_Close]) #contains the prediction values for validation (3rd column = Close),  for single-step prediction\n",
    "    \n",
    "    # Convert the x and y to numpy arrays\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    return x, y\n",
    "\n",
    "# Generate training data and test data\n",
    "x_train, y_train = partition_dataset(sequence_length, train_data)\n",
    "x_test, y_test = partition_dataset(sequence_length, test_data)\n",
    "\n",
    "# Print the shapes: the result is: (rows, training_sequence, features) (prediction value, )\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "# Validate that the prediction value and the input match up\n",
    "# The last close price of the second input sample should equal the first prediction value\n",
    "print(x_train[1][sequence_length-1][index_Close])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quello di GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features=np_data\n",
    "#target= np_data[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TimeseriesGenerator(features, target, length=2, sampling_rate=1, batch_size=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.10, random_state=123, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#win_length= 3\n",
    "#batch_size=1\n",
    "#num_features=4\n",
    "#train_generator = TimeseriesGenerator(x_train, y_train, length=win_length, sampling_rate=1, batch_size=batch_size)\n",
    "#test_generator = TimeseriesGenerator(x_test, y_test, length=win_length, sampling_rate=1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_generator[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.Sequential()\n",
    "#model.add(tf.keras.layers.LSTM(128, input_shape= (win_length, num_features), return_sequences=True))\n",
    "#model.add(tf.keras.layers.LeakyReLU(alpha=0.5)) \n",
    "#model.add(tf.keras.layers.LSTM(128, return_sequences=True))\n",
    "#model.add(tf.keras.layers.LeakyReLU(alpha=0.5)) \n",
    "#model.add(tf.keras.layers.Dropout(0.3)) \n",
    "#model.add(tf.keras.layers.LSTM(64, return_sequences=False))\n",
    "#model.add(tf.keras.layers.Dropout(0.3)) \n",
    "#model.add(tf.keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1643, 1, 12)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[1] * x_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\monob\\anaconda3\\envs\\tesi\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# Configure the neural network model\n",
    "model = Sequential()\n",
    "\n",
    "# Model with n_neurons = inputshape Timestamps, each with x_train.shape[2] variables\n",
    "n_neurons = x_train.shape[1] * x_train.shape[2]\n",
    "#print(n_neurons, x_train.shape[1], x_train.shape[2])\n",
    "model.add(LSTM(128, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2]))) \n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\monob\\anaconda3\\envs\\tesi\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1643 samples, validate on 182 samples\n",
      "Epoch 1/10\n",
      "1643/1643 [==============================] - 1s 515us/step - loss: 7.6920e-04 - val_loss: 5.0178e-04\n",
      "Epoch 2/10\n",
      "1643/1643 [==============================] - 0s 172us/step - loss: 7.5847e-04 - val_loss: 5.0446e-04\n",
      "Epoch 3/10\n",
      "1643/1643 [==============================] - 0s 170us/step - loss: 7.5798e-04 - val_loss: 5.0196e-04\n",
      "Epoch 4/10\n",
      "1643/1643 [==============================] - 0s 169us/step - loss: 7.5846e-04 - val_loss: 5.7548e-04\n",
      "Epoch 5/10\n",
      "1643/1643 [==============================] - 0s 170us/step - loss: 7.5909e-04 - val_loss: 5.3896e-04\n",
      "Epoch 6/10\n",
      "1643/1643 [==============================] - 0s 172us/step - loss: 7.5377e-04 - val_loss: 5.2809e-04\n",
      "Epoch 7/10\n",
      "1643/1643 [==============================] - 0s 172us/step - loss: 7.5693e-04 - val_loss: 5.4604e-04\n",
      "Epoch 8/10\n",
      "1643/1643 [==============================] - 0s 189us/step - loss: 7.5615e-04 - val_loss: 5.4508e-04\n",
      "Epoch 9/10\n",
      "1643/1643 [==============================] - 0s 194us/step - loss: 7.5249e-04 - val_loss: 5.3312e-04\n",
      "Epoch 10/10\n",
      "1643/1643 [==============================] - 0s 172us/step - loss: 7.5202e-04 - val_loss: 5.0346e-04\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 16\n",
    "early_stop = EarlyStopping(monitor='loss', patience=5, verbose=1)\n",
    "history = model.fit(x_train, y_train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test, y_test)\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = x_train[np.random.choice(x_train.shape[0], 1, replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.0749782 , -0.01905918, -0.04681275, -0.01982379,\n",
       "         -0.03410853, -0.00495336,  0.0083792 , -0.01464816,\n",
       "         -0.00674893, -0.00648762,  0.01478783, -0.02169625]]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\monob\\anaconda3\\envs\\tesi\\lib\\site-packages\\shap\\explainers\\tf_utils.py:28: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras is no longer supported, please use tf.keras instead.\n"
     ]
    }
   ],
   "source": [
    "e = shap.DeepExplainer(model, background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.DeepExplainer(model, x_train[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\monob\\anaconda3\\envs\\tesi\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:631: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "shap_values = explainer.shap_values(x_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[ 3.12540693e-04, -1.43026093e-04, -2.85605769e-05,\n",
       "           1.53281997e-05, -7.12927256e-06,  1.80044889e-06,\n",
       "          -5.40593608e-05,  6.39686338e-05,  3.84253043e-05,\n",
       "          -2.58249877e-05, -5.98728663e-05,  2.68136272e-05]]])]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'base_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-09f62f536042>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mshap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplots\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaterfall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tesi\\lib\\site-packages\\shap\\plots\\_waterfall.py\u001b[0m in \u001b[0;36mwaterfall\u001b[1;34m(shap_values, max_display, show)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[0mbase_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshap_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshap_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'base_values'"
     ]
    }
   ],
   "source": [
    "shap.plots.waterfall(shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
